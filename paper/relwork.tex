\section{Related Work}
\label{sec:relwork}
The algorithm used in this paper, Sway~\cite{chen2018sampling}, is a
method for search-based software engineering.
Search based software engineering (SBSE) was first proposed by Harman and
Jones~\cite{harman2001search} in 2001. SBSE transforms a software
engineering problem to a search problem to apply metaheuristic search.
A software engineering problem can be reformed as a search problem by
defining the following: a representation of the problem, a fitness
function, and a set of manipulation operators. Common algorithms include
random search, simulated annealing, genetic algorithms.

The advantage of metaheuristic algorithms is that they can explore
multiple objectives simultaneously. Multiple-objective evolutionary
algorithms (MOEA) are used in SBSE to help achieve multi-objective
optimization (MOO). In multi-objective problems, there usually isn't a
single optimal solution~\cite{marler2004MOOsurvey}, a set of optimal
points, such as the pareto frontier, is determined. 


\subsection{Random Projection}
% https://en.wikipedia.org/wiki/Random_projection

Random projection is a method used to reduce the dimensionality of the
data while preserving the relative distances between data points.
Dimension reduction can be used on various kinds of data.
One of the most well known methods is principal component
analysis~\cite{bingham2001random}. Principal component analysis finds
axis along which data displays the most variance to preserve the maximum
amount of information. 

\subsection{Semi-Supervised Learning}
% https://www.molgen.mpg.de/3659531/MITPress--SemiSupervised-Learning.pdf
Semi supervised learning is a hybrid of supervised and unsupervised
learning. Supervised learning consists of labeled data, learners or
classifiers extract patterns based on the labels. Methods such as
decision trees or support vector machines are categorized as supervised
learning. Unsupervised learning consists of data without labels. Semi
supervised learning combines both labeled and unlabeled data to build
classifiers~\cite{zhu2005semi}. This can be useful when it is costly to
generate labels for all data. Semi supervised learning can achieve better
performance and accuracy compared to unsupervised learning.

% \subsection{Why Heuristics Work}
% % http://library.mpib-berlin.mpg.de/ft/gg/gg_why_2008.pdf
% Heuristics provide us with a strategy logic to analyze a given problem.
% While heuristics may not always provide us with the optimal solution to
% a problem